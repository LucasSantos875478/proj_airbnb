# Projeto Airbnb üöÄ

## √≠ndice üèπ
  - <a href="#contextualiza√ß√£o-do-projeto-airbnb">Contextualiza√ß√£o do Projeto Airbnb</a>
  - <a href="#dados-utilizados">Dados Utilizados</a>
  - <a href="#tecnologias-utilizadas">Tecnologias Utilizadas</a>
  - <a href="#bibliotecas-utilizadas">Bibliotecas Utilizadas</a>
  - <a href="#explica√ß√£o-do-andamento-do-projeto">Explica√ß√£o do Projeto</a>
  - <a href="#an√°lise-explanat√≥ria-e-tratamento-dos-outliers">An√°lise Explanat√≥ria e Tratamento dos Outliers</a>
  - <a href="#explica√ß√£o-das-ias">Explica√ß√£o das IAs</a>
  - <a href="#deploy">Deploy</a>
  - <a href="#aprendizados">Aprendizados</a>
  - <a href="#ol√°-eu-sou-o-lucas-üëã">Sobre Mim</a>

## Contextualiza√ß√£o do Projeto Airbnb
O objetivo deste projeto √© determinar o pre√ßo de di√°ria de im√≥veis com base em suas caracter√≠sticas espec√≠ficas. O projeto visa ajudar pessoas do Rio de Janeiro e n√£o tem foco em impresas imobili√°rias, mas sim em pessoas normais que ou querem disponibilizar um im√≥vel no Airbnb ou pessoas que querem alugar um im√≥vel por alguns dias e querem verificar se o valor cobrado est√° dentro do normal. Este projeto visa facilitar a vida de pessoas que desejam alugar ou disponibilizar im√≥veis de maneira r√°pida e eficiente, proporcionando uma avalia√ß√£o precisa dos valores de di√°rias.



## Dados Utilizados
Para baixar a base de dados, acesse o link https://www.kaggle.com/datasets/allanbruno/airbnb-rio-de-janeiro. Clique no √≠cone de download e, em seguida, organize todos os arquivos '.csv' na pasta denominada 'dataset'. A base de dados disponibilizada ser√° fundamental para treinar a Intelig√™ncia Artificial, permitindo que ela aprenda padr√µes e realize an√°lises relacionadas aos pre√ßos de di√°rias de im√≥veis. Essa base de dados consolidada tem mais de 100 colunas, ent√£o n√£o ser√° poss√≠vel explicar cada coluna da base, por√©m mais para frente da documenta√ß√£o do projeto irei detalhar como analisei e exclui as colunas que n√£o ajudariam o nosso modelo de IA.

## Tecnologias Utilizadas

Escolhi Python como linguagem principal para meu c√≥digo em Ci√™ncia de Dados devido √† sua versatilidade e efic√°cia no ecossistema dessa √°rea. A vasta gama de bibliotecas especializadas, como NumPy, Pandas e Scikit-Learn, oferece ferramentas poderosas para manipula√ß√£o de dados, an√°lise estat√≠stica e implementa√ß√£o de modelos preditivos, simplificando significativamente o desenvolvimento e a execu√ß√£o de tarefas complexas.

Al√©m disso, a comunidade ativa e o suporte robusto em Python proporcionam recursos valiosos, facilitando a resolu√ß√£o de problemas e a implementa√ß√£o de solu√ß√µes inovadoras. A sintaxe clara e leg√≠vel de Python contribui para um c√≥digo mais compreens√≠vel, promovendo a colabora√ß√£o e a manuten√ß√£o eficiente do projeto em Ci√™ncia de Dados.

## Bibliotecas utilizadas
Instale as bibliotecas utilizadas no projeto, como o projeto √© extenso existem v√°rias bibliotecas para serem instaladas, algumas bibliotecas utilizadas no projeto j√° vem instaladas no python por padr√£o, destas usaremos a datetime e a pathlib. Para realizar as instala√ß√µes abra o cmd e digite:

```bash
  pip install pandas
```
```bash
  pip install numpy
```
```bash
  pip install matplotlib
```
```bash
  pip install seaborn
```
```bash
  pip install scikit-learn
```
```bash
  pip install joblib
```
```bash
  pip install streamlit
```



# Explica√ß√£o do andamento do  projeto
Como a base de dados tinha mais de 100 colunas precisei analisar coluna por coluna para entender se aquela coluna iria trazer uma informa√ß√£o importante ou n√£o para o modelo, j√° que para uma IA muita informa√ß√£o pode acabar prejudicando seu desempenho, visto que com muita informa√ß√£o ela pode acabar ficando muito lenta para conseguir dar um resultado ou at√© mesmo tenha sua eficacia prejuidaca pelo escesso de informa√ß√£o. Tendo em vista esse fator decidi excluir os seguites grupos de colunas:

1- ID, Links e colunas que n√£o possuem uma informa√ß√£o relevante para o modelo

 2- Colunas com as mesmas informa√ß√µes ou com informa√ß√µes parecidas. EX: Data x Ano/M√™s

 3- Colunas com texto livre, pois n√£o faremos uma an√°lise de palavras ou algo parecido

 4- Colunas que possuem todos ou quase todos os valores com mesmo valor/vazios

Depois dessa exclus√£o a nossa base de dados foi de mais de 100 colunas para 33 colunas, um n√∫mero muito menor e com apenas informa√ß√µes que poderiam ser ut√©is para o modelo, agora √© o momento de analisar se nos nossos dados existiam valores nulos, pois os modelos de intelig√™ncia arficial n√£o conseguem trabalhar com valores nulos ent√£o tinha que indentificar esses valores e ver como poderiamos tratr√°-los.
E na nossa base de dados existiam muitos valores nulos, v√°rias estavam com valores nulos como pode ser visto na imagem abaixo:

![Nome_imagem](imagens/valores_nulos.jpg)

Ent√£o tomei as seguintes decis√µes para os valores nulos na base de dados:

1- como temos muitos valores nulos em algumas colunas, compensa excluir essas colunas, pois caso preenchecemos com algum tipo de par√¢metro poderiamos prejudicar o nosso modelo

2- para as outras colunas que temos poucos NaN vamos excluir a linha inteira, pois temos mais de 900 mil linhas, e essa pequena quantidade que ser√° exclu√≠da n√£o afetara nosso modelo

Depois com a nossa base de dados tratada comecei a fazer a an√°lise explanat√≥ria dos dados e entender o que eu faria com os outliers das colunas
## An√°lise Explanat√≥ria e Tratamento dos Outliers
Comecei analisando a correla√ß√£o de cada coluna, para ter um melhor entendimento das informa√ß√µes e entender o que fazer depois disso. 
![Nome_imagem](imagens/grafico_correlacao.png)

Com a an√°lise desse gr√°fico consegui ter uma no√ß√£o geral de como cada coluna poderia influenciar no preco do im√≥vel, por mais que a IA teria que conseguir descrever isso √© muito importante ter uma no√ß√£o pois a IA poderia acabar tendo algum erro que eu n√£o fosse perceber caso n√£o tivesse uma no√ß√£o b√°sica do projeto.

Depois disso comecei a fazer as an√°lises dos outliers de cada coluna dos dados da seguinte forma:

1. Excluir outliers (usaremos como regra, valores abaixo de Q1 - 1.5 * Amplitude e valores acima de Q3 + 1.5 * Amplitude). Amplitude = Q3 - Q1

2. Confirmar se todas as features que temos fazem realmente sentido para o nosso modelo ou se alguma delas n√£o vai nos ajudar e se devemos excluir

Para cada coluna gerei os seguintes gr√°ficos (vou usar duas colunas como exemplo, mas o raciocinio foi o mesmo para todas as colunas):
![Nome_imagem](imagens/grafico_caixa_accommodates.png)

Com esse gr√°fico entendia como estavam dispersos os valores dentro da base de dados e sempre que os outliers iriam prejudicar o nosso modelo eu excluia para sempre deixar a base de dados o melhor poss√≠vel para a nossa IA.

![Nome_imagem](imagens/grafico_barra_accommodates.png)

Depois eu analisava como os nossos dados ficaram na nossa base de dados depois da exclus√£o dos outliers, importante lembrar que nem todos os outliers foram excluidos, apenas aqueles que poderiam prejudicar a nossa IA.

![Nome_imagem](imagens/grafico_caixa_price.png)
![Nome_imagem](imagens/grafico_histograma_price.png)

Para a nossa coluna de 'Pre√ßo' tive o mesmo cuidado para entender o que os outliers diziam e qual era o objetivo final do nosso modelo. Repeti esse processo para todas as colunas da nossa tabela e depois cheguei no processo de encoding.

Para as colunas que possuiam um texto precisei ajustar as features para facilitar o trabalho do modelo futuro (features de categoria, true e false, etc.)

- Features de Valores True ou False, vamos substituir True por 1 e False por 0.
- Features de Categoria (features em que os valores da coluna s√£o textos) vamos utilizar o m√©todo de encoding de vari√°veis dummies

Vari√°veis dummies, tamb√©m conhecidas como vari√°veis indicadoras ou vari√°veis bin√°rias, s√£o utilizadas para representar categorias em uma forma num√©rica no contexto da an√°lise de dados. 


## Explica√ß√£o das IAs
No decorrer do projeto, testamos tr√™s modelos de intelig√™ncia artificial, adotando essa abordagem para assegurar que, caso uma das IAs n√£o atendesse nossos requisitos, ter√≠amos alternativas dispon√≠veis. Utilizamos os seguintes par√¢metros para avaliar a efic√°cia das IAs:

R¬≤ (Coeficiente de Determina√ß√£o): Quanto mais pr√≥ximo de 100%, melhor a assertividade da IA. Por exemplo, uma IA com R¬≤ de 60% √© considerada inferior a uma com R¬≤ de 80%.

Erro Quadr√°tico M√©dio (RMSE): Uma m√©trica que avalia a precis√£o do modelo de regress√£o. Um RMSE menor indica uma melhor capacidade do modelo em ajustar-se aos dados observados.

Tempo de Resposta: Em casos de semelhan√ßa entre R¬≤ e RMSE, o tempo de resposta √© utilizado como crit√©rio de desempate.

 Os modelos utilizados nesse projeto foram o ExtraTrees, RandomForest e o LinearRegression, abaixo teremos uma tabela com os resultados dos par√¢metros utilizados    
| IA   | R¬≤       | RSME      |  Tempo      |  
| :---------- | :--------- | :--------- | :--------- |
| ExtraTrees | 97.03% | 47.33 | 24 segundos
| RandomForest  | 96.75% | 49.51 | 6 segundos
| LinearRegression  | 34.95% | 221.52 | 0.248637 segundos

Percebemos que o modelo LinearRegression teve um tempo de resposta menor do que 1 segundo, mas sua acertividade (R¬≤) de 34.95% √© muito baixo e seu RSME de 221.52 √© extremamente alto, ent√£o optei por n√£o usar esse modelo. Os modelos ExtraTrees e RandomForest foram muito parecidos tanto no R¬≤ visto que s√£o 97,03% e 96,75% respectivamente, quanto no RSME 47,33 e 49,51 e com uma diferen√ßa bem baixa em quest√£o do tempo, por conta desses valores analisados optei por usar o ExtraTrees como modelo de previs√£o.
## Deploy
Durante o deploy da IA, optei por incorporar a biblioteca 'streamlit' para desenvolver um micro-site. Essa escolha foi motivada pela praticidade de criar uma interface intuitiva contendo todas as informa√ß√µes necess√°rias para a previs√£o da di√°ria. Al√©m disso, a utiliza√ß√£o do micro-site oferece uma abordagem mais organizada, simplificando o acesso √†s funcionalidades da IA sem exigir conhecimentos avan√ßados em programa√ß√£o. 

Imagens para mostrar como ficou o resultado final:
![Nome_imagem](imagens/ia1.jpg)
![Nome_imagem](imagens/ia2.jpg)
![Nome_imagem](imagens/ia3.jpg)

## Aprendizados
A cria√ß√£o deste modelo de intelig√™ncia artificial foi uma experi√™ncia extremamente gratificante e divertida. Ao aplicar meus conhecimentos em Python e explorar diversas bibliotecas, pude enfrentar desafios significativos, sendo a an√°lise explorat√≥ria de dados um dos momentos mais complexos. Esse processo demandou tempo, aten√ß√£o e paci√™ncia, pois compreendi a import√¢ncia desses dados para o treinamento das IAs. Mesmo diante das dificuldades, n√£o desisti. Este √© meu primeiro projeto, e sinto uma grande evolu√ß√£o. Estou ansioso para os pr√≥ximos desafios que enfrentarei e para continuar aprendendo.

# Ol√°, eu sou o Lucas! üëã
Aos 19 anos, trilho meu caminho na Ci√™ncia de Dados com paix√£o pela programa√ß√£o. Com habilidades avan√ßadas em Python e conhecimento intermedi√°rio em SQL, enfrento desafios com entusiasmo, especialmente na cria√ß√£o de intelig√™ncia artificial. Embora meu ingl√™s seja inicial, estou dedicado aos estudos para aprimor√°-lo. Estou aqui para aprender, crescer e deixar minha marca na interse√ß√£o entre dados e inova√ß√£o.

## Links para me contatar üîó 
[![github](https://img.shields.io/badge/github-000?style=for-the-badge&logo=github&logoColor=white)](https://github.com/LucasSantos875478)
[![linkedin](https://img.shields.io/badge/linkedin-0A66C2?style=for-the-badge&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/lucas-santos-454584285/)
[![instagram](https://img.shields.io/badge/instagram-1DA1F2?style=for-the-badge&logo=instagram&logoColor=)](https://www.instagram.com/lucassantos875478/)
